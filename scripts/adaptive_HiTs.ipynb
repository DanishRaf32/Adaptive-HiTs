{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Adaptive HiTS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code written by Danish Rafiq and Asif Hamid\n",
    "\n",
    "This script simulates the adaptive HiTS (AHiTS) method for several benchmark models. The code is a part of the paper: \"Hierarchical deep learning based adaptive time-stepping of multiscale systems\", Hamid A., Rafiq D., Nahvi SA., Bazaz MA. 2023, submitted to Nonlinear Dynamics\n",
    "\n",
    "This script is build upon the multiscale AHiTs created by Yuying Liu (Liu Y, Kutz JN, Brunton SL.,2022 Hierarchical deep learning of multiscale differential equation time-steppers. Phil. Trans. R. Soc. A 380: 20210200.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import ResNet as net\n",
    "from aHiTs import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid system\n"
     ]
    }
   ],
   "source": [
    "# adjustables\n",
    "dt = 0.01                     # time unit\n",
    "noise = 0.0      #noise levels: 0.0, 0.01, 0.02, 0.05 ,0.1, 0.2\n",
    "system = 'Hyperbolic'         # system name: 'Hyperbolic', 'Cubic', 'VanDerPol', 'Hopf', 'KS'\n",
    "\n",
    "if system =='Hyperbolic':\n",
    "    tol=1e-5\n",
    "elif system =='Cubic':\n",
    "    tol=5e-4\n",
    "elif system =='VanDerPol':\n",
    "    tol=8e-2\n",
    "elif system =='Hopf':\n",
    "    tol=5e-3\n",
    "elif system =='Ks':\n",
    "    tol=8e-6\n",
    "else:\n",
    "    print(\"please select a valid system\")\n",
    "\n",
    "# tolerance for AHiTs: 5e-3 for Hopf, 8e-2 for VanDerPol, 5e-4 for cubic, 1e-5 for hyperbolic, 8e-6 for KS (for more details, see discussion section of the paper)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# path\n",
    "data_dir = os.path.join('../../data/', system)\n",
    "model_dir = os.path.join('../../models/', system)\n",
    "\n",
    "# global const\n",
    "ks = list(range(11))\n",
    "step_sizes = [2**k for k in ks]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### load data & models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/Hyperbolics\\\\val_noise0.0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[115], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m     test_data \u001B[38;5;241m=\u001B[39m test_data[\u001B[38;5;28;01mNone\u001B[39;00m, :, :]\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 16\u001B[0m     val_data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval_noise\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoise\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     test_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_noise\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(noise)))\n",
      "File \u001B[1;32m~\\PycharmProjects\\HiTS\\venv\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[0;32m    403\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 405\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    406\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../data/Hyperbolics\\\\val_noise0.0.npy'"
     ]
    }
   ],
   "source": [
    "#load validation data set and test set\n",
    "if system == 'KS':\n",
    "    val_data = np.load(os.path.join(data_dir, 'data.npy')).T\n",
    "    mean_values = val_data.mean(0)\n",
    "    ranges = val_data.ptp(0)\n",
    "    val_data = (val_data - mean_values)/ranges\n",
    "    val_data = val_data[None, :, :]\n",
    "\n",
    "\n",
    "    test_data = np.load(os.path.join(data_dir, 'data.npy')).T\n",
    "    mean_values = test_data.mean(0)\n",
    "    ranges = test_data.ptp(0)\n",
    "    test_data = (test_data - mean_values) / ranges\n",
    "    test_data = test_data[None, :, :]\n",
    "else:\n",
    "    val_data = np.load(os.path.join(data_dir, 'val_noise{}.npy'.format(noise)))\n",
    "    test_data = np.load(os.path.join(data_dir, 'test_noise{}.npy'.format(noise)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load models\n",
    "models = list()\n",
    "for step_size in step_sizes:\n",
    "    print('loading model_D{}.pt'.format(step_size))\n",
    "    models.append(torch.load(os.path.join(model_dir, 'model_D{}_noise{}.pt'.format(step_size, noise)),map_location='cpu'))\n",
    "\n",
    "# fix model consistencies trained on gpus (optional)\n",
    "for model in models:\n",
    "    model.device = 'cpu'\n",
    "    model._modules['increment']._modules['activation'] = torch.nn.ReLU()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### benchmarks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shared info\n",
    "n_steps = test_data.shape[1] - 1\n",
    "t = [dt*(step+1) for step in range(n_steps)]\n",
    "criterion = torch.nn.MSELoss(reduction='none')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds_mse = list()\n",
    "times = list()\n",
    "print('uniscale forecasting...')\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "    y_preds = model.uni_scale_forecast(torch.tensor(test_data[:, 0, :]).float(), n_steps=n_steps)\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "    preds_mse.append(criterion(torch.tensor(test_data[:, 1:, :]).float(), y_preds).mean(-1))\n",
    "print('prediction recorded!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#AHiTs\n",
    "#adaptive time-stepping calculation\n",
    "start=time.time()\n",
    "steps_used, index, indices_ahits = adaptive_multi_scale_forecast(val_data=val_data, n_steps=n_steps, models=models, best_mse=tol, dt=dt, step_sizes=step_sizes)\n",
    "end=time.time()\n",
    "ahits_offline = end - start\n",
    "print('steps used: {}'.format(steps_used))\n",
    "start=time.time()\n",
    "# interative vectorized computations\n",
    "y_preds_aHiTs, ahits_online = adaptive_multi_scale_online(val_data=val_data, test_data=test_data[:,0,:], n_steps=n_steps, models=models, dt=dt, step_sizes=step_sizes, steps_used=steps_used, index=index)\n",
    "end=time.time()\n",
    "ahits_time = end - start\n",
    "print('AHiTs completed')\n",
    "\n",
    "#calculate errors\n",
    "mse_aHiTs = criterion(torch.tensor(test_data[:, 1:, :]).float(), y_preds_aHiTs[:,1:n_steps+1,:]).mean(-1)\n",
    "aHiTs_err = mse_aHiTs.mean(0).detach().numpy()\n",
    "norm_ahits=aHiTs_err.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize forecasting error at each time step\n",
    "norm_uni=list()\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "colors=iter(plt.cm.rainbow(np.linspace(0, 1, len(ks))))\n",
    "mean_pointwise=list()\n",
    "\n",
    "#Figure1: error plot\n",
    "for k in range(len(preds_mse)):\n",
    "    err = preds_mse[k]\n",
    "    mean = err.mean(0).detach().numpy()\n",
    "    norm_uni.append(mean.mean())  #mean\n",
    "    mean_pointwise.append(mean)\n",
    "    rgb = next(colors)\n",
    "    plt.plot(t, np.log10(mean), linestyle='-', color=rgb, linewidth=5, label='$\\Delta\\ t$={}dt'.format(step_sizes[k]))\n",
    "plt.plot(t, np.log10(aHiTs_err), linestyle='-', color='k', linewidth=6, label='AHiTs')\n",
    "plt.legend(fontsize=30, loc='upper center', ncol=6, bbox_to_anchor=(0.5, 1.2))\n",
    "plt.xticks(fontsize=60)\n",
    "plt.yticks(fontsize=60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#figure2: Time response\n",
    "idx = 8 # (you need to change the code here accordingly as state variables are different for different systems)\n",
    "t = np.linspace(0, (n_steps-1)*dt, n_steps)\n",
    "if system == 'KS':\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    ax1.imshow(np.squeeze(test_data.T))\n",
    "    ax1.set_title(\"Ground Truth\")\n",
    "    ax1.set_xlabel('t')\n",
    "    ax1.set_ylabel('x')\n",
    "    ax2.imshow(np.squeeze(y_preds_aHiTs.T))\n",
    "    ax2.set_xlabel('t')\n",
    "    ax2.set_ylabel('x')\n",
    "    ax2.set_title(\"AHiTs\")\n",
    "else:\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    gs = gridspec.GridSpec(nrows=1, ncols=1, hspace=0.5)\n",
    "    ax0 = fig.add_subplot(gs[0, :])\n",
    "    if test_data.shape[2]==3:\n",
    "        ax0.plot(t, test_data[idx, 1:, 0], 'r-', linewidth=10, label='x')\n",
    "        ax0.plot(t, test_data[idx, 1:, 1], 'g-', linewidth=10, label='y')\n",
    "        ax0.plot(t, test_data[idx, 1:, 2], 'b-', linewidth=10, label='z') #only in case of Hopf\n",
    "        ax0.plot(t, y_preds_aHiTs[idx, :n_steps, 0].detach().numpy(), 'k--', linewidth=10, label='AHiTs')\n",
    "        ax0.plot(t, y_preds_aHiTs[idx, :n_steps, 1].detach().numpy(), 'k--', linewidth=10)\n",
    "        ax0.plot(t, y_preds_aHiTs[idx, :n_steps, 2].detach().numpy(), 'k--', linewidth=10)\n",
    "    else:\n",
    "        ax0.plot(t, test_data[idx, 1:, 0], 'r-', linewidth=10, label='x')\n",
    "        ax0.plot(t, test_data[idx, 1:, 1], 'g-', linewidth=10, label='y')\n",
    "        ax0.plot(t, y_preds_aHiTs[idx, :n_steps, 0].detach().numpy(), 'k--', linewidth=10, label='AHiTs')\n",
    "        ax0.plot(t, y_preds_aHiTs[idx, :n_steps, 1].detach().numpy(), 'k--', linewidth=10)\n",
    "\n",
    "    ax0.legend(fontsize=50, loc='upper right')\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=60)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#computational time\n",
    "for i in range(len(times)):\n",
    "    print('single scaled model (Dt={}): computing time {}s'.format(step_sizes[i]*dt, times[i]))\n",
    "print('AHiTs:  {}s'.format(ahits_online))\n",
    "\n",
    "#norms\n",
    "norm_uni[0]=preds_mse[0][:,1:].mean()\n",
    "for i in range(len(norm_uni)):\n",
    "    print('MSE of NNTS (Dt={}): {}'.format(step_sizes[i]*dt, norm_uni[i]))\n",
    "print('MSE of AHiTs: {}'.format(norm_ahits))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
